{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Image batch dimensions: torch.Size([32, 3, 224, 224])\n",
      "Image label dimensions: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms,models\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm  # Importing tqdm for progress bar\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import time\n",
    "#from torchsummary import summary as summary_\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "IMG_SIZE = 224\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "dataset_name=dict()\n",
    "dataset_name['cifar10']=datasets.CIFAR10\n",
    "dataset_name['cifar100']=datasets.CIFAR100\n",
    "\n",
    "dataset_outdim=dict()\n",
    "dataset_outdim['cifar10']=10\n",
    "dataset_outdim['cifar100']=100\n",
    "\n",
    "##############################################################\n",
    "batch_size = 32\n",
    "data_choice='cifar100'\n",
    "mevit_isload=False\n",
    "max_epochs = 100  # Set your max epochs\n",
    "\n",
    "backbone_path=f'vit_{data_choice}_backbone.pth'\n",
    "start_lr=5e-5\n",
    "weight_decay=1e-4\n",
    "# Early stopping parameters\n",
    "early_stop_patience = 5\n",
    "early_stop_counter = 0\n",
    "best_val_accuracy = 0.0\n",
    "##############################################################\n",
    "# # 1. Data Preparation and Pretrained ViT model\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_dataset = dataset_name[data_choice](root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: 32\n",
      "Image label dimensions: 32\n"
     ]
    }
   ],
   "source": [
    "for image, label in test_loader:\n",
    "    print('Image batch dimensions:', len(image))\n",
    "    print('Image label dimensions:', len(label))\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
