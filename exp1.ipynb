{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################################\n",
    "# Scenario1: Temperature Scaling + entropy -> make dynamic ensemble of models which entropy is less than threshold\n",
    "\n",
    "#step1: find T vector\n",
    "\n",
    "#step2: find entropy threshold of total\n",
    "\n",
    "#step3: sum of softmax vector of each good model(under threshold) -> final inference from softmax vector sum\n",
    "\n",
    "####################################################################\n",
    "# Scenario2: MC Dropout -> find confident EE -> static ensemble \n",
    "\n",
    "#step1: make MC Dropout model\n",
    "\n",
    "#step2: find confident EE from experiment\n",
    "\n",
    "#step3: sum of softmax vector of each good model(under threshold) -> final inference from softmax vector sum\n",
    "\n",
    "####################################################################\n",
    "# Scenario3: train new block to choose which exit to inference (JUST SCENARIO, NOT VERIFIED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models,datasets, transforms\n",
    "from mevit_model import MultiExitViT\n",
    "from tqdm import tqdm\n",
    "####################################################################\n",
    "IMG_SIZE = 224\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "dataset_name=dict();dataset_name['cifar10']=datasets.CIFAR10;dataset_name['cifar100']=datasets.CIFAR100;dataset_name['imagenet']=datasets.ImageNet\n",
    "dataset_outdim=dict();dataset_outdim['cifar10']=10;dataset_outdim['cifar100']=100;dataset_outdim['imagenet']=1000\n",
    "##############################################################\n",
    "################ 0. Hyperparameters ##########################\n",
    "##############################################################\n",
    "batch_size = 1024\n",
    "data_choice='cifar100'\n",
    "mevit_isload=True\n",
    "mevit_pretrained_path=f'integrated_ee.pth'\n",
    "\n",
    "backbone_path=f'vit_{data_choice}_backbone.pth'\n",
    "start_lr=1e-4\n",
    "max_iter=200\n",
    "\n",
    "ee_list=[0,1,2,3,4,5,6,7,8,9]#exit list ex) [0,1,2,3,4,5,6,7,8,9]\n",
    "exit_loss_weights=[1,1,1,1,1,1,1,1,1,1,1]#exit마다 가중치\n",
    "exit_num=11\n",
    "##############################################################\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize(IMG_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "train_dataset = dataset_name[data_choice](root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = dataset_name[data_choice](root='./data', train=False, download=True, transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Load the pretrained ViT model from the saved file\n",
    "pretrained_vit = models.vit_b_16(weights=models.ViT_B_16_Weights.DEFAULT)\n",
    "\n",
    "if data_choice != 'imagenet':\n",
    "    pretrained_vit.heads.head = nn.Linear(pretrained_vit.heads.head.in_features, dataset_outdim[data_choice])  # Ensure output matches the number of classes\n",
    "\n",
    "    # Load model weights\n",
    "    pretrained_vit.load_state_dict(torch.load(backbone_path))\n",
    "    pretrained_vit = pretrained_vit.to(device)\n",
    "#from torchinfo import summary\n",
    "#summary(pretrained_vit,input_size= (64, 3, IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "model = MultiExitViT(pretrained_vit,num_classes=dataset_outdim[data_choice],ee_list=ee_list,exit_loss_weights=exit_loss_weights).to(device)\n",
    "# Assume a pretrained model (replace with your own model)\n",
    "model.load_state_dict(torch.load('integrated_ee.pth'))  # Load your trained weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  \r"
     ]
    }
   ],
   "source": [
    "# Initialize lists to store outputs from each exit and labels\n",
    "output_list_list = [[] for _ in range(exit_num)]\n",
    "labels_list = []\n",
    "\n",
    "# Run inference on the test set and collect the logits from each exit\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Collecting logits\", leave=False):\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        output_list = model(images)  # Get the output from all exits\n",
    "        \n",
    "        # Store the output from each exit\n",
    "        for i in range(exit_num):\n",
    "            output_list_list[i].append(output_list[i])\n",
    "        \n",
    "        # Store the labels\n",
    "        labels_list.append(labels)\n",
    "\n",
    "# Concatenate the collected outputs and labels\n",
    "output_list = [torch.cat(output_list_list[i]) for i in range(exit_num)]\n",
    "labels = torch.cat(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 100])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_list[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 리스트를 바이너리 파일로 저장하기\n",
    "file_path = 'cache_[tensor([10000,100])x11].pt'\n",
    "torch.save(output_list, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "11\n",
      "torch.Size([10000, 100])\n"
     ]
    }
   ],
   "source": [
    "# 저장한 파일을 다시 불러오기\n",
    "loaded_tensor_list = torch.load(file_path)\n",
    "\n",
    "# 데이터 확인\n",
    "print(type(loaded_tensor_list))  # <class 'list'>\n",
    "print(len(loaded_tensor_list))   # 11\n",
    "print(loaded_tensor_list[0].shape)  # torch.Size([10000, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "# Ensemble the outputs from all exits by averaging and applying softmax\n",
    "# Assuming exit_num is 11\n",
    "ensemble_logits = sum(output_list) / exit_num\n",
    "ensemble_probabilities = F.softmax(ensemble_logits, dim=1)\n",
    "\n",
    "# Now, output_list contains the logits from each exit, labels contains the true labels,\n",
    "# and ensemble_probabilities contains the ensembled predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Accuracy: 87.44%\n"
     ]
    }
   ],
   "source": [
    "_, predicted_labels = torch.max(ensemble_probabilities, dim=1)\n",
    "correct_predictions = (predicted_labels == labels).sum().item()\n",
    "total_predictions = labels.size(0)\n",
    "accuracy = correct_predictions / total_predictions * 100\n",
    "\n",
    "print(f'Final Accuracy: {accuracy:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
