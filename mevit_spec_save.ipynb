{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. 모델 로드 및 전처리 등 실험과 상관 없는 내용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm  # Importing tqdm for progress bar\n",
    "from mevit_model import MultiExitViT\n",
    "from Dloaders import Dloaders\n",
    "IMG_SIZE = 224\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "dataset_name = {'cifar10':datasets.CIFAR10, 'cifar100':datasets.CIFAR100,'imagenet':None}\n",
    "dataset_outdim = {'cifar10':10, 'cifar100':100,'imagenet':1000}\n",
    "##############################################################\n",
    "################ 0. Hyperparameters ##########################\n",
    "batch_size = 1\n",
    "data_choice = 'cifar100'\n",
    "mevit_pretrained_path=f'models/{data_choice}/integrated_ee.pth'\n",
    "\n",
    "backbone_path=f'models/{data_choice}/vit_{data_choice}_backbone.pth'\n",
    "ee_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  # exit list ex) [0,1,2,3,4,5,6,7,8,9]\n",
    "exit_loss_weights = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]  # exit마다 가중치\n",
    "\n",
    "##############################################################\n",
    "if __name__ == '__main__':\n",
    "    train_loader,test_loader = Dloaders(data_choice=data_choice,batch_size=batch_size,IMG_SIZE=IMG_SIZE)\n",
    "\n",
    "    # Load the pretrained ViT model from the saved file\n",
    "    pretrained_vit = models.vit_b_16(weights=None)\n",
    "    pretrained_vit.heads.head = nn.Linear(pretrained_vit.heads.head.in_features, dataset_outdim[data_choice])  # Ensure output matches the number of classes\n",
    "\n",
    "    # Load model weights\n",
    "    pretrained_vit.load_state_dict(torch.load(backbone_path))\n",
    "    pretrained_vit = pretrained_vit.to(device)\n",
    "    \n",
    "    model = MultiExitViT(pretrained_vit, num_classes=dataset_outdim[data_choice], ee_list=ee_list, exit_loss_weights=exit_loss_weights).to(device)\n",
    "    model.load_state_dict(torch.load(mevit_pretrained_path))    \n",
    "    \n",
    "    model.eval()\n",
    "    running_metric = [0.0] * model.exit_num\n",
    "    len_data = len(test_loader.dataset)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        with tqdm(test_loader, unit=\"batch\", leave=False) as t:\n",
    "            for xb, yb in t:\n",
    "                xb, yb = xb.to(device), yb.to(device)\n",
    "                output_list = model(xb)\n",
    "                accs = [output.argmax(1).eq(yb).sum().item() for output in output_list]\n",
    "                running_metric = [sum(x) for x in zip(running_metric, accs)]\n",
    "                \n",
    "                t.set_postfix(accuracy=[round(100 * acc / len(xb),3) for acc in accs])\n",
    "\n",
    "    running_acc = [100 * metric / len_data for metric in running_metric]\n",
    "    print(f'total Test Accuracy: {running_acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. MEVIT의 각 출구들에서의 Precision을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. MEVIT의 각 출구들까지의 FLOPs 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
